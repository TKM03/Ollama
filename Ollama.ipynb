{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2679d877-0cbd-4549-9c57-cba0c0a6ea6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\dell-intern-hr\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell-intern-hr\\anaconda3\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell-intern-hr\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell-intern-hr\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell-intern-hr\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell-intern-hr\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell-intern-hr\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Install necessary Python packages\n",
    "!pip install requests tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee9916b-ca2e-4a85-ba99-3e7b0957f2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'mistral' is ready to use.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Ollama API URL\n",
    "OLLAMA_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Check if Ollama is running\n",
    "def is_ollama_running():\n",
    "    try:\n",
    "        response = requests.get(f\"{OLLAMA_URL}/api/tags\")\n",
    "        return response.status_code == 200\n",
    "    except requests.exceptions.RequestException:\n",
    "        return False\n",
    "\n",
    "# Start Ollama if not running\n",
    "if not is_ollama_running():\n",
    "    print(\"Ollama is not running. Start it by running 'ollama serve' in your terminal.\")\n",
    "\n",
    "# Pull the Mistral model (or any other LLM like Gemma, LLaMA)\n",
    "model_name = \"mistral\"\n",
    "response = requests.post(f\"{OLLAMA_URL}/api/pull\", json={\"name\": model_name})\n",
    "if response.status_code == 200:\n",
    "    print(f\"Model '{model_name}' is ready to use.\")\n",
    "else:\n",
    "    print(f\"Error pulling model: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe246e77-7613-4a22-84e9-bf597f2fe864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: A fun fact about AI is that in 1950, mathematician Alan Turing proposed a test to determine if a machine could be considered intelligent: the Turing Test. In this test, a human evaluator would judge natural language conversations between a human and a machine, aiming to decide if the machine was intelligent enough to pass as human. However, it's important to note that today, there are various types of AI that don't rely on natural language, such as image recognition or self-driving cars.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "OLLAMA_URL = \"http://localhost:11434\"\n",
    "\n",
    "def generate_text(prompt, model=\"mistral\", max_tokens=100):\n",
    "    \"\"\"\n",
    "    Generate text using a local LLM model via Ollama.\n",
    "    Handles streaming response correctly.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"stream\": True  # Enable streaming mode\n",
    "    }\n",
    "\n",
    "    response = requests.post(f\"{OLLAMA_URL}/api/generate\", json=data, stream=True)\n",
    "\n",
    "    generated_text = \"\"\n",
    "\n",
    "    # Read the response line by line\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            try:\n",
    "                # âœ… Correctly decode JSON using Python's built-in `json.loads()`\n",
    "                json_data = json.loads(line.decode(\"utf-8\"))\n",
    "                generated_text += json_data.get(\"response\", \"\")\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding line: {line} -> {e}\")\n",
    "\n",
    "    return generated_text.strip()\n",
    "\n",
    "# ðŸ”¹ Test with a sample prompt\n",
    "prompt = \"Tell me a fun fact about AI.\"\n",
    "result = generate_text(prompt)\n",
    "print(\"Generated Text:\", result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7146e200-8981-44c4-8dd8-dbe7a78e42b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [07:38<00:00, 114.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: What is Generative AI?\n",
      "Response: Generative AI refers to a class of artificial intelligence systems that can generate new content, such as images, text, or music, based on patterns and structures learned from the data they were trained on. Unlike traditional AI models which focus on understanding or predicting outcomes, generative AI models learn to create new examples within the same domain as their training data, often by using techniques like deep learning and neural networks.\n",
      "\n",
      "For instance, a text-generating generative AI model could be trained on novels, news articles, and other written works, then use that knowledge to generate its own unique pieces of text, such as creating a new short story or writing an email based on the given context. Similarly, an image-generating generative AI model could produce original artwork by learning from various images it was exposed to during training.\n",
      "\n",
      "Generative AI has potential applications in many fields, including art, entertainment, marketing, and scientific research, as it can help create realistic simulations, generate personalized content, or even assist in the design process. However, as with any powerful technology, ethical considerations and potential misuses must also be addressed when working with generative AI systems.\n",
      "\n",
      "\n",
      "Prompt 2: Tell me a joke about AI.\n",
      "Response: Why don't machines ever get tired? Because they recharge their batteries, not themselves! \\*laughs\\* That's a classic one! But seriously, it's always fascinating to think about how far artificial intelligence has come and where it might be heading in the future. It's a truly exciting time for technology enthusiasts like us!\n",
      "\n",
      "\n",
      "Prompt 3: How do LLMs work?\n",
      "Response: LLMs, or Law Masters/Masters of Laws, are postgraduate law degrees pursued by individuals who have already completed their first law degree (usually an LLB or JD). The purpose of an LLM is to provide specialized knowledge and skills in a specific area of law.\n",
      "\n",
      "Here's how it typically works:\n",
      "\n",
      "1. Admission requirements: To be admitted into an LLM program, students usually need to have completed their first law degree from a recognized institution, with good academic standing. Some universities may also require applicants to have work experience in the field they want to specialize in.\n",
      "\n",
      "2. Specialization: LLM programs offer a range of specializations, such as international law, human rights law, corporate law, intellectual property law, and tax law, among others. Students choose a specific area of interest and focus their studies on that subject matter.\n",
      "\n",
      "3. Coursework: LLM courses may include lectures, seminars, and workshops, where students learn from experienced professors and practitioners. The coursework is designed to provide in-depth knowledge and practical skills related to the chosen specialization.\n",
      "\n",
      "4. Research project or thesis: Many LLM programs require students to complete a research project or thesis on a topic related to their specialization. This project demonstrates the student's ability to conduct independent legal research, analyze complex legal issues, and present their findings in a coherent and persuasive manner.\n",
      "\n",
      "5. Duration: The duration of an LLM program varies depending on the institution and the country. In some countries, an LLM can be completed in one year, while in others it may take up to two years.\n",
      "\n",
      "6. Benefits: An LLM degree can enhance a lawyer's knowledge and skills in a particular area of law, making them more competitive in the job market. It can also provide opportunities for career advancement, as well as open doors to international legal practice. Additionally, an LLM can be a valuable credential for academics who wish to pursue a career in teaching or research.\n",
      "\n",
      "\n",
      "Prompt 4: Give me a short poem about technology.\n",
      "Response: In the realm where dreams and logic meet,\n",
      "\n",
      "Lies the power that we call technology.\n",
      "A silent whisper of thought and light,\n",
      "Guiding us through the day and night.\n",
      "\n",
      "Invisible threads weave connections wide,\n",
      "Bridging oceans and time with a single stride.\n",
      "Through screens, ideas ignite and flow,\n",
      "In this digital symphony, knowledge grows.\n",
      "\n",
      "Yet, in its grasp, some feel lost and cold,\n",
      "A disconnect that the heart often holds.\n",
      "Remembering, as we scroll and click,\n",
      "That human touch remains the true trick.\n",
      "\n",
      "So let's use this gift with humble grace,\n",
      "Connecting souls in love and space.\n",
      "For technology is just a tool,\n",
      "To share dreams, to build, and to rule.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "prompts = [\n",
    "    \"What is Generative AI?\",\n",
    "    \"Tell me a joke about AI.\",\n",
    "    \"How do LLMs work?\",\n",
    "    \"Give me a short poem about technology.\"\n",
    "]\n",
    "\n",
    "responses = []\n",
    "for p in tqdm(prompts):\n",
    "    response = generate_text(p, max_tokens=50)\n",
    "    responses.append(response)\n",
    "\n",
    "# Display results\n",
    "for i, (p, r) in enumerate(zip(prompts, responses)):\n",
    "    print(f\"\\nPrompt {i+1}: {p}\\nResponse: {r}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab23b4b3-bb7e-41fd-b414-92e40988c4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
